POSIX多线程程序设计
===================


在计算机专用术语中，线程是指机器中连续的、顺序的属性集合。一个线程包含执行一系列机器指令必须的机器状态，包括当前指令位置、地址和数据寄存器等。一个UNIX进程可以理解为一个线程加上地址空间、文件描述符和其他数据。

- **任何两个彼此独立运行的操作是异步的。真正的并行只能在多处理器系统中存在，但是并发可以在单处理器系统和多处理器系统中都存在。同步就是让线程协调地完成工作的机制**并发能够在单处理器系统中存在是因为并发实际上是并行的假象，并行要求程序能够同时执行多个操作，而并发只要求程序能够假装同时执行多个操作。

- 在多处理器系统中开发程序的并行性。除了并行性这一优点是需要特殊硬件支持外，其他优点对硬件不做要求。

- 可扩展性遵循Amdahl法则。该法则表明让每个线程做相对独立、无须频繁同步的一大块工作，要比让它们做小块工作能获得更好的并行。多处理器系统的硬件必须提供一些同步访问内存的机制，当每个处理器有自己的数据告诉缓存时，其中的数据必须与其他处理器缓存的数据以及内存中的数据保持一致。

- 线程代码中的负荷代价包括由于线程间同步所导致的直接影响，几乎任何线程代码中你都需要使用某种同步机制，使用太多的同步很容易损失性能。还可能包含更多的细微影响。（23页）

- 一个进程中的所有线程共享地址空间，线程间没有保护界限，如果一个线程使用未初始化的指针写内存，可能会破坏其他线程的堆栈或堆空间。

- 最适合使用线程的是实现以下功能的应用

>- 计算密集型应用，为了能在多处理器系统上运行，将这些计算分解到多个线程中实现；
>- I/O密集型应用，为提高性能，将I/O操作重叠，很多线程可以同时等待不同的I/O操作。分布式服务器应用就是很好的实例，它们必须响应多个客户的请求，必须为通过慢速网络连接主动提供I/O做好准备。


- **线程系统的三个基本要素：执行环境、调度和同步。**

##线程

-  大部分时间内，线程ID保存在共享（静态或外部）变量中，或着保存在堆空间的结构体中。

- 分离一个正在运行的线程不会对线程带来任何影响，仅仅是通知系统当该线程结束时，其所属资源可用被回收。分离线程意味着通知系统不再需要此线程，允许系统将分配给它的资源回收。

- 为确保终止线程的资源对进程可用，应该在每个线程结束时分离它们。一个没有被分离的线程终止时会保留其虚拟内存，包括它们的堆栈和其他系统资源。

- 少数情况下，多个线程需要知道某个特定线程何时结束，则这些线程应该等待某个条件变量，被等待的线程应该将其返回值（或任何其他信息）保存在某个公共的位置，并将条件变量广播给其他在其上等待的线程以唤醒它们。

- 线程状态：
 
 >- 就绪，线程能够运行，但在等待可用的处理器，可能刚刚启动，或刚刚从阻塞中恢复，或者被其他线程抢占。
 
 >- 运行，线程正在运行，在多处理器系统中，可能有多个线程处于运行状态。
 
 >- 阻塞，线程由于等待处理器外的其他条件无法运行，如条件变量的改变、加锁互斥量或I/O操作结束。
 
 >- 终止，线程从起始函数中返回，或调用pthread_exit()，或者被取消，终止自己并完成所有资源清理工作，不是被分离，也不是被连接，一旦线程被分离或者连接，它就可以被收回。
 
 -  如果你希望在初始线程终止时，进程中的其他线程继续执行，则需要在初始线程中调用pthread_exit()而不是从main函数中返回。
 - 线程大部分时间处在就绪、运行和阻塞三个状态。当一个运行线程被抢占时，如被时间片机制抢占（因为它已经运行足够长的时间），线程立即进入就绪状态。

- 线程在以下情况是被阻塞：

>- 试图加锁一个已经被锁住的互斥量；
>- 等待某个条件变量；
>- 调用singwait等待尚未发生的信号；
>- 执行无法立即完成的I/O操作；
>- 内存页错误之类的系统操作而被阻塞。

- 当处理器可用时，主线程或者立即执行或者等到创建的线程终止后重新运行直到结束。

- 线程通常从启动函数中返回来终止自己。线程在调用完每个清理过程后也将进入终止态。如果线程已经被分离，则它立刻进入回收，否则，线程处于终止态， 它还可以被其他线程调用连接。当创建不需要连接的线程时，应该使用detachstate属性建立线程使其自动分离。

- 如果有其他线程在等待连接进入终止态的线程，则该其他线程将被唤醒。如果终止线程没有被分离，则它将一直处于终止态直到被分离或者被连接。线程一旦被分离就不能再访问它了。

- 回收将释放所有在线程终止时未释放的系统和进程资源，包括保存线程返回值的内存空间、堆栈、保存寄存器的内存空间等。其中一些资源可能已经在线程终止时被释放，在线程终止后上述资源就不该被访问了。

- 一旦线程被回收，线程ID就无效了，不能再连接它、取消它或者执行其他任何操作。而终止线程ID（可能是系统数据结构地址）可能被分给新的线程。

- 互斥量、条件变量和信号灯可以由任何线程销毁，只要它们诶解锁并没有线程等待，但是只有互斥量的主人能够解锁它，如果线程终止还有加锁的互斥量，则该互斥量就不能被再次使用（因为不被解锁）。

##同步

- 不变量是由程序作出的假设，特别是有关变量组间关系的假设，当编写队列包时，你需要某些特殊数据。你需要为每个队里指定一个队列头指针，指向队列第一个元素，每一个数据元素也包含指向下一个元素的指针。重要的并不完全是数据，程序还需要依赖于数据之间的关系。上述关系就是队列包中的不变量。

- 当程序遇到被破坏的不变量时，系统可能会返回错误结果甚至立即失效。

- 临界区（有时称“串行区域”）是指影响共享数据的代码段。临界区总能够对应到一个数据不变量，反之亦然。同步机制使你的程序免于访问被破坏的不变量。如果一定要（临时的）破坏某个不变量，你需要锁住一个互斥量；当其他线程需要访问该不变量时，它也要试图锁住一个互斥量，此时线程就会一直等待，直到你将互斥量解锁并恢复不变量的值后才能访问不变量。

- 不能拷贝互斥变量，因为使用拷贝的互斥量是不确定的，可以拷贝指向互斥量的指针，这样就可以使多个函数或线程共享互斥量来实现同步。

- 如果有其他文件使用互斥量，则将其声明为外部类型；如果仅在本文件内使用，则将其声明为静态类型。

-  当确信没有线程在互斥量上阻塞时，可以立刻释放它。在程序中，调用sched_yield意味着：如果有等待处理的用户输入，则主线程运行，处理用户请求；如果用户没有输入请求，则该函数立即返回。

- 为了让不变量总是为真，对其组成数据的修改必须是原子性的。如果没有对硬件、结构的丰富知识和对指令执行的控制，甚至无法确保对程序状态的单个修改原子化。“|原子”是指不可分割，但在此处意味着现场不会看到令他困惑的东西。

-  我们所说的”原子性“意味着即使当多个线程同时运行在多个处理器上时，其他线程也不会发现被破坏（中间状态或者不一致状态）的不变量。当硬件无法支持不可分割或不可中断的操作时，有两种基本方法实现上述目的：一种是当检测到被破坏的不变量时重新再试；一种是重建原始状态，除非你对处理器结构有深入了解或者不想写可移植代码，否则很难可靠地实现以上目的。

- 当没有办法确保真正原子性时，你需要自己建立机制。当需要“原子化”地更新数组元素和索引时，只有保证互斥量加锁时执行操作即可。

- 任何对不变量感兴趣的线程在修改或检测不变量状态时都必须使用同一个互斥量。互斥量应该尽量少，够用即可，每个互斥量保护的区域则尽量大；互斥量本质是串行执行，如果互斥量保护的数据（或代码）包含彼此无关的片段，则可以将大的互斥量分解为几个小的 互斥量来提高性能，这样任意时刻需要小互斥量的线程减少，线程等待的时间就会减少，所以互斥量足够多，每个互斥量保护区域应尽量少。

- 按照相反的顺序解锁有利于减少线程做回退操作的可能性。“链锁”是层次锁的一个特殊实例，即两个锁的作用范围互相交叠。当平衡或修剪树型结构时，可以使用层次锁；当搜索某个节点时，可以使用链锁。仅当多个线程几乎总是活跃在层次中的不同部分时才应该使用链锁。

- 条件变量是用来通知共享数据状态信息的，可以使用条件变量来通知队列已空、或队列非空、或任何其他需要由线程处理的共享数据状态。

- 解锁和等待操作必须是原子性的，以防止其他线程在该线程解锁之后、阻塞之前锁住互斥量，这样其他线程才能够唤醒它。等待条件变量总是返回锁住的互斥量。

- 在一个条件变量上等待会导致以下原子操作：释放相关互斥量，等待其他线程发给该条件变量的信号（唤醒一个等待者）或广播该条件变量（唤醒所有等待者）。当等待条件变量时，互斥量必须始终锁住；当线程从条件变量等待中醒来时，它重新继续锁住互斥量。

- 条件变量就是允许使用队列的线程之间交换队列状态信息的机制。条件变量的作用是发信号不是互斥。

- 互斥量不仅与条件变量一起使用，而且还要单独使用；通常一个互斥量可以与多个条件变量相关。一个条件变量应该与一个谓词相关，如果试图将一个条件变量与多个谓词相关或将多个条件变量与一个谓词相关，就会陷入死锁或竞争问题的危险。所以当你在多个谓词之间共享一个条件变量时，必须总是使用广播，而不是发信号，信号比广播有效。

- 动态初始化静态声明的条件变量必须确保每个条件变量在使用之前初始化且仅初始化一次。如果需要使用非默认属性初始化条件变量，必须使用动态初始化。

- 在线程从列表中删除了一个包含条件变量的节点后，然后广播唤醒所有等待线程，此时释放条件变量（在释放它占有空间之前）是安全的，也是很好的主意，被唤醒线程在继续执行时应该检查等待的谓词，所有必需确保没有释放该谓词需要的资源，这可能需要额外的同步。

- 当线程等待条件变量时，它必须将相关互斥量锁住，在阻塞线程之前，条件变量等待操作将解锁互斥量；而在重新返回线程之前，会再次锁住互斥量。所有并发地（同时）等待同一个条件变量的线程必须指定同一个相关互斥量。任何条件变量在特定时刻只能与一个互斥量相关联，而互斥量则可以同时与多个条件变量关联。

- 应该总是在循环中等待条件变量，来避免程序错误、多处理器竞争和假唤醒。线程从条件变量返回之前总是锁住互斥量，即使等待超时，在超时之后等待一个锁住的互斥量将导致超时等待比你要求的时间长很多。

- 当只有一个线程需要被唤醒来处理改变后的状态（而任何等待线程都可以做这个工作）时，使用发信号。如果你为多个谓词条件使用一个条件变量，则不能使用发信号操作，因为你不能分辨是应该唤醒等待这个谓词条件的线程，还是唤醒等待那个谓词条件的线程。

- 如果向队列中增加一个元素，而且只有等待该元素的线程在条件变量上阻塞，则可以使用发信号来唤醒一个线程，而让其他线程继续等待，以避免不必要的环境切换，另一方面，如果向队列中增加多个元素，你可能需要广播。

- 当一个等待线程被唤醒的时候，它必须首先加锁互斥量，如果线程被唤醒而此时通知线程仍然锁住互斥量，则被唤醒线程会立刻阻塞在互斥量上。针对这种情况，当互斥量锁住时，将线程直接从条件变量等待队列中移到互斥量等待队列中，不需要任何环境切换。如果互斥量不被锁住，任何线程（不仅是被唤醒的线程）可以在被唤醒线程之前锁住互斥量，这将是一个产生被拦截唤醒的根源。

- pthread提供了一些关于内存可视性的基本规则：
>- 当线程调用pthread_create时，它所能看到的内存值也是它建立的线程能够看到的，任何在你调用pthread_create之后向内存写入的数据，可能不会被建立的线程看到，即使写操作发生在启动新线程之前。
>- 当线程解锁互斥量时看到的内存中的数据，同样也能被后来直接锁住（或通知等待条件变量锁住）相同互斥量的线程看到。同样，在解锁互斥量之后写入的数据不会被其他线程看到，即使写操作发生在其他线程锁互斥量之前。
>- 线程终止（或者通过取消操作，或者从启动函数中返回，或者调用pthread_exit）时看到的内存数据，同样能够被连接该线程的其他线程（通过pthread_join）看到。当然，终止后写入的数据不会被连接线程看到，即使写操作发生在连接之前。
>- 线程发信号或广播条件变量时看到的内存数据，同样可以被唤醒的其他线程看到。而在发信号或广播之后写入的数据不会被唤醒的线程看到，即使写操作发生在线程被唤醒之前。

- 任何时候两个线程需要访问相同数据时，你就需要应用其中一条内存可视化规则，大多数情况下指使互斥量，这不仅是为了保护多个写操作，即使线程只是读数据，它也要锁住互斥量以确保读到最新的数据值。

- 单一线程中，即在完全同步的程序中，在任何时间读写任何内存都是安全的，即如果某个内存地址写入数据，然后在某个时刻从相同的内存地址读取数据，它总是能够得到最后更新的数据。

- 一个内存地址一次只能保存一个值，不要让线程竞争以优先获得访问权。如果两个处理器向同一内存地址写不同的数据，则不同的数据将分别保存在二者的高速缓存中，最终两个值将写到主存中，但是是在随机的时刻写入，与写到相应的高速缓存中的顺序无关。

- 所有在设置内存屏障之前发起的内存访问，必须先于在设置屏障之后发起的内存访问之前完成。内存屏障是一堵移动墙，而不是刷新cache的命令，而是将一组操作排序。内存控制器不能删除内存屏障，不能越过它，直到完成在内存屏障之前的所有操作。

##使用线程的几种方式

- 线程编程模型
>- 流水线。每个线程反复地在数据系列集上执行同一种操作，并把操作结果传递给下一步骤的其他线程，这就是“流水线”方式。

>- 工作组。每个线程在自己的数据上执行操作，工作组中的线程可能执行同样的操作，也可能执行不同的操作，但是它们一定独立地运行。由于所有的工作线程在不同数据部分上执行相同的操作，这种模式叫SIMD（单指令多数据流）并行处理。   

>- 客户端/服务器。一个客户为每一件工作与一个独立的服务器“订契约”，通常“订契约”是匿名的一个请求通过某种接口提交。
>所有上述模型可以任意方式组合或修改来满足个人的要求。流水线可能包含向服务器线程提交请求，服务器线程可能使用工作组方式，一个或多个工作线程可能使用一条流水线，或者一个并行的搜索“引擎”可能启动多个线程，每个尝试不同的搜索算法。

##线程高级编程

- 在传统的顺序编程中，一次性初始化经常通过使用布尔变量来管理。控制变量被静态地初始化为0，而任何依赖于初始化的代码都能测试该变量。如果变量值仍然为0，则它能实行初始化，然后变量置为1，以后检查的代码将跳过初始化。

- 可以用一个布尔变量和一个静态初始化的互斥量来编写一次性初始化代码。使用pthread_once不能静态地初始化一个互斥量。因此为初始化互斥量需要pthread_mutex_init,必须仅仅初始化一次，所以初始化调用应在一次性初始化代码中进行。pthread_once函数首先检查控制变量，以判断是否已经完成初始化，当该函数成功返回时，调用者能够肯定所有状态已经初始化完毕。

- 同步使用一个条件变量的两个线程必须使用一样的互斥量，等待一个条件变量会自动地解锁、然后加锁相关的互斥量。如果互斥量没有与PTHREAD_PROCESS_SHARED一起被创建，同步不会工作。

- 当创建已经知道不需要取消或连接的线程时，应该以分离的方式创建它们，如果你提供自己的通知机制，如使用一个条件变量，仍然能创建可分离的线程。

**设置堆栈大小不是可移植的***所需的栈空间数量取决于每个系统使用的调用标准和数据格式。**设置堆栈地址将减低可移植性**在从上向下的栈空间的机器上，指定的地址应该是栈的最高地址，而不是最低地址，如果栈增大，需要指定最低地址。

- pthread支持三种取消模式：off（关），取消pending被推迟直到启用取消模式；defend（延迟），在下一个取消点执行取消；asynchronous（异步），可以随时执行取消。模式为二进制编码，称为“取消状态”和“取消类型”，每种模式实质上包括开关两种状态。取消状态可以是“启用”或”禁用“，取消类型可以是被”推迟“或”异步“。

- 从一个锁住互斥量的终止线程中恢复数据的唯一方法是：应用程序能分析所有的共享数据并且恢复它到一个一致、正确的状态。除了应用程序设计者在进程中控制每一位共享状态的嵌入式系统外，通常是不实际的，你不仅要重建自己程序或库的状态，而且需要重建可能被线程调用的任何库函数的状态。

- 当作为一个取消点的函数检测到一个未解决的取消请求，函数将不返回调用者，如果有任何活跃的清除函数，就调用它们，线程终止。

- 你只能取消创建的线程，或线程创建者（或线程自己）给了你一个标识符，这通常意味着取消被限制在一个子系统内操作。如果需要保证取消不能在一个特别的取消点或取消点的一些顺序期间发生，可以暂时在代码的那个区域停用取消。

- pthread规定的异步取消安全的函数是pthread_cancel、pthread_setcancelstate和pthread_setcanceltype(并且启用异步取消时，没有必要调用pthread_cancel）。

- DEC线程是开放软件基础（OSF）的分布式计算环境（DEC )的一个关键部件，被设计为独立于内在的UNIX核心。当DEC被移植到支持线程（然而并非支持Pthread）的新内核时，通常省略用户模式I/O包装器，导致线程在不支持推迟取消的内核内阻塞。

- 当编写任何库代码时，应将其设计为可以优雅地处理推迟取消。在不适当的地方停用取消，并且总是在取消点使用清除处理器。当线程在等待一个条件变量时被取消，它将被唤醒，并保持互斥量加锁状态。在线程终止前，通常需要恢复不变量，且它总是需要释放互斥量。

- 可以把每个线程考虑为有一个活动的清除处理函数的栈。控制结构被所有的线程使用来维护共享同步对象和不变量。

- 函数cleanup_handler作为每个线程的取消处理函数被安装。当线程被取消或正常结束时，该函数被调用，减少活动的线程数并且解锁互斥量。函数pthread_routine建立cleanup_handler作为活动的取消清除处理函数。

- 只要设置pthread_cleanup_pop的参数非零，则即使没有发生取消，清除处理函数仍将被调用。

- 当单线程程序中的一个函数需要创造私有数据时，该私有数据在对该函数的调用之间一致，数据能静态地分配在存储器中。命名范围可能限制于使用它的函数或文件（静态）或者它能被全局使用（extern）。

- 一个线程真正拥有的唯一私有存储是处理器寄存器，甚至栈地址也能被共享，在任何情况下，寄存器和”私有“堆栈都不能代替非线程代码中使用的持久静态存储。因此，当需要一个私有变量时，必须首先决定所有的线程是否共享相同的值，或者线程是否应该有它自己的值。如果它们共享变量，则可以使用静态或外部数据，然而，必须同步跨越多线程对共享数据的存取，通常通过增加一个或多个互斥量来完成。如果每个线程都需要一个私有变量值，则必须在某处存储所有的值，并且每个线程一定能定位合适的值。

- 键对于所有线程是相同的，但是每个线程能将它独立的键值与共享键联系。每个线程能在任何时间为键改变它的私有值，而不会运行键或任何另外线程拥有的键值。

- 如果需要创建一个线程私有数据键，必须保证pthread_key_create对于每个pthread_key_t变量仅仅被调用一次。因为如果将一个键创建两次，其实是在创建两个不同的键，第二个将覆盖第一个，第一个键与任何线程可能为其设置的值一起将永远地丢失。一次性初始化函数（pthread_once)被用来保证键在第一次存取前被创建。

- pthread标准保证在一次只有128个线程私有数据键。当释放线程私有数据键时，不会影响任何线程对该键设置的当前值，甚至不影响调用线程的当前键值。仅当你肯定没有线程持有该键的值时，才能删除线程私有数据键，否则根本别释放它们。

- 线程私有数据值为空（NULL）对于pthread意味着一些特殊的东西，所以除非你确实需要，不要将一个线程私有数据置空。

- 当一个线程退出时，它有一些为线程私有数据键定义的值，通常需要处理它们。如果键值是指向堆存储器的指针，需要释放存储器避免每次线程终止时留下内存泄漏。

- 当一个线程退出时，pthread在进程中检查所有的线程私有数据键，并且将所有不是空的线程私有数据键置为空，然后调用键的destructor函数，因为被调用的destructor顺序是未定义的，所以试着使每个destructor尽可能独立。

- 通常把**实时编程**划分为两个独立的范畴：”硬实时“服务要求的水平和反应时间被实际中或同等不可妥协的一些东西定义；”软实时“意味着你大部分时间需要满足调度要求，但是如果不能后果也不是很严重。

- 当有SCHED_FIFO或SCHED_RR策略的线程在一个条件变量上等待或等待加锁同一个互斥量时，它们将以优先级顺序被唤醒。

- 不能独立于线程的参数来修改一个执行线程的调度策略，为了调度正确操作，策略和参数一定是一致的，每个雕塑策略有一个优先级的惟一范围，并且一个线程不能以一个对当前调度策略而言无效的优先级执行。为保证策略和参数的一致性，它们被设置于单个调用中。

- 实时调度除策略和参数之外还有竞争范围和分配域。前者描述了线程为处理器资源而竞争的方式。后者是系统内线程可以认为其竞争的处理器的集合。一个系统可以有一个以上的分配领域，每个包含一个以上的处理器，在一个单处理器系统内，分配域只包含一个处理器，但是你仍然可以有多个分配域，在一台多处理器机上，各个分配域可以包含从一个处理器到系统中所有的处理器。系统竞争范围是可预知的，进程竞争范围是低廉的。系统竞争范围在一个大于1的分配域内有更少的可预言性。

- 当一个线程被分配到超过一个处理器的分配域时，应用程序不能再依靠完全可预知的调度行为。如果可预测性时关键的，无论如何都应该使用系统竞争范围。

- 依靠实时调度的问题之一是它不是模块化的。另一个是优先级调度的方式，固定优先级调度的一个更严重的问题被称为优先级倒置。它是指一个低优先级线程能阻止一个高优先级线程的执行，它是调度和同步直接的一个不干净的相互作用结果。调度规则要求一个线程运行，但是同步要求运行另行的线程，所以两个线程的优先级好像被颠倒了。

- 需要优先级调度时可以记住：
>- 进程竞争范围比系统竞争范围”更好，因为你将不会阻止其他线程或内核中的某个线程运行。
>- SCHED_RR比SCHED_FIFO“更好”，并且更具有可移植性，因为SCHED_RR线程将在与具有相同优先级的线程共享可用处理器时间间隔中被抢占。
>- 对SCHED_FIFO和SCHED_RR策略而言，低优先级比高优先级好，因为这更少可能妨碍另外重要的东西。
>除非你代码确实需要优先级调度，否则应避免使用它。在大多数情况下，与它将解决的问题相比，优先级调度将引起更多的问题。

- “优先级上限”协议意味着当一个线程拥有互斥量时，它将以指定的优先级运行。当任何线程锁住与该属性对象相关定义的一个互斥量时，线程的优先级将被设置为互斥量的优先级ceiling，除非线程的优先级已经是相同或更高的。注意，在高于互斥量优先级ceiling的线程内加锁互斥量会打破协议，失去对优先级倒置的保护。

- “优先级继承”意味着，当一个线程在由另一个低优先级线程拥有的互斥量上等待时，后者的优先级将被增加到等待线程的优先级。当任何线程试图加锁互斥量、同时一个低优先级线程拥有该互斥量时，只有它拥有互斥量，当前拥有互斥量的线程的优先级将被提高到等待线程的优先级。在优先级继承协议中，当一个线程锁住一个互斥量时，线程的优先级就被互斥量控制，当另外的线程在那个互斥量上阻塞时，它会查看拥有互斥量的线程的优先级.如果拥有互斥量的线程比试图在互斥量上阻塞的线程优先级低，则拥有互斥量的线程的优先级将被提升到阻塞线程的优先级。

- “优先级保护”协议意味着当使用优先级ceiling创建一个互斥量时，你要指定当线程锁住互斥量时可以运用的最高优先级。任何锁住互斥量的线程将自动地将它的优先级提高到那个值，这将允许在它在被任何另外试图加锁该互斥量的线程抢占以前，完成对互斥量的操作。你还可以检验或修改使用优先级ceiling（保护）协议创建的互斥量的优先级ceiling。

- 如果任何比ceiling高的优先级运行的线程锁住优先级ceiling互斥量，协议将破坏，对于优先级倒置的所有保护都被取消了。当设计代码时，优先级ceiling能被安全地判断，并且与更一般的方案相比，使用更少的性能开销来避免优先级倒置。当然，通过避免使用优先级调度或仅仅在相等优先级的线程内使用给定的互斥量，可以避免优先级倒置，而且总是最有效的方式。

- 当线程解锁互斥量时，线程的优先级自动被降到它原来的优先级，高优先级等待线程被唤醒。如果又有一个更高优先级的线程在互斥量上阻塞，则拥有互斥量的线程将再次增加优先级，当互斥量被解锁时，线程仍然回到它原来的优先级。

- 优先级继承协议比优先级ceiling更通用和强大，当然也更复杂和昂贵。如果一个函数库必须使用优先级调度，并且无法避免从不同优先级的线程内使用同一互斥量，则优先级继承是目前惟一可用的方案。如果你正在写一个主程序，并且知道你的互斥量不会被函数库内创建的线程加锁，则优先级ceiling将和优先级继承完成相同的结果，且带来更少的开销。

- 当你要求并发但不需要并行时，多对一实现可以提供最好的线程创建性能和因互斥量和条件变量带来的环境切换效率。因为pthread库全部在用户模式下保存和恢复线程的环境，所以它是快的。

- 多对一模型优点：最快的环境切换时间；简单实现甚至可以是（大部分）可移植。缺点：系统服务阻塞期间潜在的长延迟；单个过程应用程序不能利用多处理机硬件。

- 一对一线程映射有时也被称为一个“内核线程"实现。pthread库把每个线程分派到一个核实体。通常它必须使用阻塞式内核功能在互斥量和条件变量上等待，由于同步可以在内核或用户模式中发生，线程调度在内核层实现。在一对一的实现中，pthread线程能充分利用多处理机硬件优势而不需要你做任何额外的努力。

- 一对一主要有两个问题：它们的可扩展性不好，即应用程序的每个线程对应一个核实体。在一个互斥量上阻塞和在一个条件变量上等待时，因为它们要求进入机器的内核保护模式，所以大多数一对一实现花费更多的开销。尤其是当加锁一个尚未锁住的互斥量，或当解锁一个没有线程等待的互斥量时，要比多对一实现更加昂贵，因为大多数系统上这些功能可以在用户模式下完成。

- 一对一模型优点：能在单个进程内利用多处理机硬件的优势；在系统服务阻塞期间没有延迟。缺点：线程环境切换速度相对较慢（调用进内核）；当使用多线程是可扩展性差，因为每个pthread线程从系统中使用核资源。

- 多对少模型试图兼有多对一模型和一对一模型的优点，同时避免它们的缺点。该模型要求建立用户水平pthread库和内核之间的合作，它们共同承担调度责任并且可以在对方之间传达线程的信息。

- 多对少模型优点：能在一个进程内利用多处理机硬件的优势；大多数环境在用户模式切换（速度快）；可扩展性好，进程可以为每个物理处理器使用一个核实体，或者更多一些；在系统服务的阻塞期间延迟很小。缺点：比其他模型复杂；程序员在核实体上失去直接的控制，因为线程的优先级可能仅仅在用户模式中有意义。

##POSIX针对线程的调整

- 除非你打算很快地exec一个新的程序，否则应避免（如果你能的话）在一个多线程的程序中使用fork。fork调用不会影响互斥量的状态，如果它在父进程中被锁住，则它在子进程中被锁！
如果一个互斥量在fork调用时被锁，则它在子进程中仍然被锁。因为一个加锁的互斥量被锁住它的线程拥有，只有锁住互斥量的线程是调用fork的那个线程时，互斥量可以在子进程中被开锁。如果当你调用fork时另外的线程把一个互斥量锁住，你将失去对该互斥量和由该互斥量控制的任何数据的存取。

- fork处理器的目的是允许线程的代码越过fork调用保护同步状态和数据不变量，而在大多数情况中都需要加锁互斥量，但是不能从信号处理函数中加锁互斥量。int pthread_atfork(void (*prepare)(void),void (*parent),void (*child)(void));
 
- 如果编写一个使用互斥量并且不建立fork处理器的子系统，则该子系统在fork调用后在子进程内将不能正确工作。prepare fork处理器以正确的顺序锁住所有的由相关代码（对一个库或一个应用程序而言）使用的互斥量以阻止死锁的发生。child fork处理器经常可以与parent fork处理器一样有时需要重置程序或库的状态。

- exec函数的功能是取消当前程序的环境并且用一个新程序代替它。对exec的调用，将很快地终止进程内除调用exec的线程外的所有线程。它们不执行清除处理器或线程私有数据destructors，线程只是简单地停止存在。

- 当你不想使用起始线程或让它等待其他线程结束时，可以通过调用pthread_exit而非返回或调用exit退出主函数。从主函数调用pthread_exit将在不影响进程内其他线程的前提下终止起始进程，运行它们继续和正常完成。

- pthread要求ANSI C标准I/O函数是线程安全的，因为stdio包需要为输出缓冲区和文件状态指定静态存储区，stdio实现将使用互斥量或信号灯等同步机制。void flockfile(FILE *file);int ftrylockfile(FILE *file）；void funlockfile(FILE *file).

- 为了在stdio内避免可能出现的死锁问题，pthread推荐你必须锁住两个文件流时，总是在输出流之前锁住输入流。

- ANSI C提供了向stdio缓冲区高效地读取个写入单个字符的函数。int getc_unlocked(FILE *stream);int getchar_unlock(void);int putc_unlocked(int c,FILE *stream);int putchar_unlcoked(int c);

- 如果想要两个线程并行地搜索一个目录，必须同步它们对传给readdir_r函数的共享struct dirent的使用。

- 用户和终端ID函数int getlogin_r(char *name,size_t namesize);char *cterrmid(char *s);  int ttyname_r(int fildes,char *name,size_t namesize);这些函数将数据返回到一个调用则指定的缓冲区中，对于函数getlogin_r，namesize必须至少是LOGIN_NAME_MAX个字符，对于ttyname_r,namesize至少是TTY_NAME_MAX个字符，每个函数在成功时返回0值，在失败时返回一个错误数字，除了可能返回的错误getlogin和ttyname，getlogin_r和ttyname_r之外还可以返回ERANGE以表明名字缓冲区太小。

- 目录搜索函数：int readdir_r(DIR *drip,struct dirent *entry,struct dirent **result);该函数返回由drip指定的目录流中的下一个目录入口。如果搜索到目录流的结尾，它返回0并将result置空，如果失败，它返回一个如EBADF之类的错误数字。

- 字符串函数char *strtok_r(char *s，const char *sep，char **lasts）；该函数返回字符串s中的下一个token。

- 时间表示函数：char *asctime_r(const struct tm *tm, char *buf); char *ctime_r(const time_t *clock,char *buf); struct tm *gmtime_r(const time_t *clock,struct tm*result);struct tem *localtime_r(const time_t *clock,struct tm *result);输出缓冲区（buf和result）由调用者提供，要求buf参数指向一个至少26个字节的字符串。

- 随机数产生函数：int read_r(unsigned int *seed);种子被维持在调用者提供的存储（seed）中，该接口的主要问题是在一个程序内让所有的应用和库代码共享单个种子通常是不实际的，导致应用程序和各个库通常产生分离的随机数流。

- 组数据库函数：int getgrgid_r(gid_t gid, struct group *grp,char *buffer,size_t bufsize,struct group **result);  int getgrnam_r(const  char *name,strcut group *grp,char *buffer,size_t bufsize,struct group **result).用户库函数：int getpwuid_r(uid_t uid,struct passwd *pwd,char *buffer,size_t bufsize,struct passwd **result); int getpwnam_r(const char *name,struct passwd *pwd,char *buffer, size_t buffsize, struct passwd **result).以上这些函数针对特定的组或用户（gid、uid或name）将组或用户记录的一个拷贝（分别是grp或pwd）保存到由参数buffer和buffsize指定的一个缓冲区中。在每种情况下。函数返回值或者为0（成功），或者为一个错误数字。缓冲区要求的最大尺寸可以通过调用sysconf函数来设置，其中参数为_SC_GETER_ R_SIZE_MAX（对于组数据）或参数为_SC_GETPW_R_SIZE_MAX(对于用户数据）。

- 当线程和信号遭遇时，仅仅在主线程内使用pthread_sigmask来屏蔽信号，然后同步地在专用线程中使用sigwait来处理信号，如果必须在线程内使用sigaction（或等价的）来处理同步信号（如SIGSEGV),要特别小心，在信号处理函数内应尽量少做工作。

- 所有信号行为都是国产范围内的。与“硬件环境”同步的信号包括SIGPPE/SIGSEGV和STGTRAP,它们被送到引起该硬件状况的线程，而绝不传给其他线程。

- 信号掩码函数：int pthread_sigmask(int how,const digset_t *set,sigset_t *oset);每个线程都有自己私有的信号掩码，可以通过该函数来修改。当一个线程被创建时，它继承了创造它的线程的信号掩码——如果你想要在所有地方屏蔽一个信号，则首先在主线程中屏蔽它。

- int pthread_kill(pthread_t thread, int sig).在一个进程内，一个线程可以通过调用该函数向一个特定的线程（包括自己）发信号。当调用该函数时，你不仅要指定传送的信号数值，还要指定目标线程的pthread_t标识符。然而你不能使用该函数向进程外的线程发送信号，因为线程标识符仅在创建它的进程内有意义。使用该函数向一个特定的线程传送SIGKILL信号将杀死整个进程，而不仅是指定的线程。

- 如果你推迟一个占有资源（如一个互斥量）的线程，将容易导致应用程序的死锁。推迟和恢复函数是调度函数不是同步函数，并且同时使用调度和同步控制会产生严重的后果。

- 同步处理异步信号函数int sigwait(const sigset_t *set,int *sig);  #ifdef _POSIX_REALTIME_SIGNALS     int sigwaitinfo(const sigset_t *set, siginfo_t *info);   int sigtimedwait(const sigset_t *set,siginfo_t *info,const struct timespec *timeout);      #endif       在多线程代码中总使用sigwait与异步信号一起工作。sigwait函数使用一个信号集作为它的参数，并且在集合中的任一信号发生时返回一个信号值。函数sigwaitinfo和sigtimedwait都返回收到信号的实时信号信息 siginfo_t.

- SIGEV_THREAD的通知机制使得信号通知函数像线程起始函数一样运行。对于任何“传统的”信号产生机制，如setitimer、SIGCHLD、SIGINT等,该机制特性是不可用的。

- 信号灯：与信号捕获函数同步：#ifdef _POSIX_SEMAPHORES
int sem_init(sem_t *sem,int pthread, unsigned int value);int sem_destroy(sem_t *sem); int sem_wait(sem_t *sem);  int sem_trywait(sem_t *sem); int sem_post(sm_t *sem);  int sem_getvalue(sem_t *sem,int *sval);      #endif

- 信号灯不同于互斥量，任何线程可以释放在一个信号灯上堵住的线程，就好像任何线程能释放某线程已锁住的互斥量一样；它还不同于条件变量，信号灯能独立于任何外部的状态条件变量依赖于一个共享的谓词和等待互斥量,而信号灯不需要。

##Real code

- 调试工具设计：首先我们将构造一个barrier用来停止线程，当要求的线程数量到达barrie时，所有程序被允许继续运行；然后我们将构造所谓的读写锁。该锁允许多个线程同时读数据，但是禁止任何线程修改正在被其他线程读或修改的数据。

- barrier是将一组成员保持一起的一种方式。通常被用来确保某些并行算法中的所有合作线程在任何线程可以继续运行之前到达算法中的一个特定点。所有线程可以执行相同的代码，线程在一些代码中处理共享数据集（如一个数组）的独立部分而在另外的代码段中并行地处理私有数据，但是另外的代码段（如并发区域的安装或清除代码）还必须保证仅仅只有一个线程执行，在这些区域之间的边界经常使用barrier来实现。

- barrier的核心是一个计数器，用来获取必须等待的线程数，当每个线程到达barrier时，计数器减1，如果计数器没有到达0，则线程等待，如果计数器为0则将唤醒所有等待线程。该计数器必须由一个互斥量来保护。

- 当一个线程锁住一个读写锁时，它选择共享读访问或者独占写访问。当有任何线程在写访问时，想要读访问的线程不能继续，当其他线程正在进行写存取或读存取时，试图获得写存取的一个线程不能继续。

- 当写锁被释放时，如果读数据者和写数据者同时正在等待存取，则读数据者被优先给予访问权。因为读访问优先有利于并发。

- 开发”工作队列"实现一组线程从同一个队列中接受工作请求，并且并行地处理它们。

- 当创建一个新的函数库时，你要做的就是小心设计以保证函数库是线程安全的。你可以决定函数需要什么状态和哪个状态需要在线程间共享、哪个状态应该被调用者通过外部环境管理，哪个状态可以被保存在本地变量中等，你可以定义接口函数以最有效的方式支持那个状态。

- 将函数库改为线程安全的最简单的技术就是把一个互斥量指派到每个子系统，当任何调用进入子系统时，锁住互斥量，从子系统退出时，解锁互斥量。因为单个互斥量涵盖了全部子系统。互斥量阻止了多个线程同时在子系统内执行。注意这种方法仅解决同步竞争，而不是顺序竞争。

- 将不安全的库转变为一个服务者线程，使那个线程成为一个代表不安全库提供能力的“服务器”。只有服务者线程调用该库，因此是否线程安全没有关系。在接口附近编写自己的“大互斥量”包装器代码，尽管结果可能是安全的，但它将是很低效的，除非你很少使用函数库，因为远程操作正在进行时，其他线程可能被锁住很长一段时间。具有永久的静态数据的函数更难于封装。使用外部状态扩展实现。

##避免调试的提示

- 避免不正确的代码

- 避免依赖“线程惯量”，在线程需要的资源被创建并恰当地初始化后，才让线程启动，这样可以看到在pthread_create调用前发生的内存写。绝不要假设你创建的线程会等待你。

- 当你写多线程代码时，应该假定在任意点上、在程序的任何语句内，每个线程可能睡眠一段不可知的时间。处理器上的时间片机制可以在任意点上将线程打断一段未指定的时间。竞争更多与内存可视性相关（于多个写操作的同步相比）。内存可视性规则：一个线程总是能看到被同一处理器上的前面执行的线程做的存储器变化。在一台单处理机上所有的线程在同样的处理器上执行，这使在调试期间检测内存可见性问题变得困难；在一台多处理器机上，只有当线程被安排到不同的处理器上执行特定的脆弱（易被破坏的）代码段时，才能看到可见性竞争。

- 除非你导致排序，线程间不存在顺序。

- 同步机制：通过确保没有其他线程能够运行直到线程阻塞自己或降低自己的优先级。调度告诉系统一个特定工作（线程）对于你的应用程序如何重要，因此它能安排你最重要的工作；同步告诉系统没有其他线程被允许进入临界区直到调用线程退出。

- 最简单形式的竞争是当多个线程在没有合适的同步前提下试图写共享状态时。使用一个互斥量保证线程不能读不一致的数据。如果你必须在线程之间共享栈数据，要确定使用数据的所有线程在从分配内存的函数返回前终止。你的线程越对称，对环境做的假设越少，这种竞争发生的机会越少。

- Amdahl法则：因为多线程编程的最大力量就是事情能并发地发生，“无序”的程序是更有效的，同步阻止了并发。如果大多数处理器在等待另一个处理器完成一些工作，则在一台多处理机上运行一个应用程序不会有很多帮助。

- 在一个pthread程序中，最常见的死锁类型是互斥量死锁即资源都是互斥量时。发生死锁的线程在原地等待，并且总是等待，而竞争中线程不正确地做了一些事情并继续前进，该问题在某段时间后才显示出来。

- 如果你一次需要锁住超过一个互斥量，可以通过使用一个严格的锁层次或回退算法避免死锁。但回退算法的缺点是：如果大量其他线程锁住互斥量，即使它们没有任何死锁的可能，回退循环可能运行很长时间。

- 当一个程序因为死锁挂起时，你需要线程调试器具有两个重要的能力，首先，应允许你在一个互斥量所有权被记录的模式下运行程序，并且可以使用调试器命令显示。如果发现一个线程拥有互斥量的同时在其他互斥量上阻塞，则这可能是你遇到死锁的指示。其次，你会希望检验拥有互斥量的线程的调用栈，以决定回来为什么仍锁住。死锁常见原因之一是一些线程没有解锁互斥量就从一个函数中返回。

- 小心优先级倒置，优先级倒置至少涉及三个具有不同优先级的线程，它是在同步与调度之间的冲突。中等优先级的线程（或它唤醒的其他线程)可以无止境地阻止低优先级线程释放互斥量。

- 避免优先级倒置的方法：完全避免实时调度；设计你的线程使不同优先级的线程不需要使用同一个互斥量；使用优先级ceiling互斥量或优先级继承，不能为不是你创建的互斥量设置优先级协议；避免调用这样的函数：它可能锁住不是你创建的互斥量并提升互斥量优先级。

- 绝不要在谓词之间共享条件变量，如果避免使用单个条件变量来管理多个谓词条件，你的代码通常更干净和更有效。

- 共享堆栈和相应的内存破坏 ，当其他线程可能仍在使用共享数据时，从共享数据堆栈分配函数中返回，将导致不可预知的后果。如果共享堆栈内存，你必须保证拥有堆栈的线程决不会在其他线程停止使用共享数据之前将共享数据从堆栈中“弹出”。

- 避免性能问题

>- 了解并发串行化
>- 使用正确数目的互斥量，加锁互斥量需要花时间而且解开互斥量需要更多的时间。加锁操作降低内存系统的效率。
>- 绝不要与缓存作对，如果两个线程在同样的缓存块中存取不同的数据，没有线程可以利用它正在使用的处理器上的缓冲拷贝。每个线程需要从主存中添满一个新的缓存，这将降低程序的速度。

## POSIX多线程快速参考

- POSIX 1003.1.c-1995选项
>pthread适用于多个领域。在高性能的计算程序中可以用它来支持多个循环的并行分解，实时应用程序可以用它支持并发的实时输入/输出，在数据库和网络服务器中可以轻易而举地用它来支持客户的并发访问，商业或软件开发程序在分时系统中可以使用其并行和并发优点。

- POSIX 1003.1c-1995限制

- POSIX 1003.1c-1995接口，这些接口是按照函数类型进行排序的：线程、互斥量等。参考格式：头部，显示了这个接口的名称；原型，显示了这个接口的全部C语言原型，描述了怎样用各种参数调用函数；描述，给了大纲摘要；表中描述了所有符号型参数可能的取值；参考，给出了本书论述该接口或相关接口的主要参考章节；头文件，说明了用这种功能编码的头文件，你需要所有列在此处的头文件；错误，描述从接口返回的错误代号，因为pthread可以区分强制性错误检测和非强制性的错误检测，这些错误会以黑体报告出来；提示，对该接口做个别的必需简单评论。

- 错误检测和报告，POSIX标准可以仔细地辨别两种类型的错误：强制性错误（包括超出程序员控制范围情况），这些错误必须总是有系统检测出来并以特别的错误代码报告出来；非强制性错误通常是由于你的错误造成的。
 
 - 使用void*类型，ANSI C允许任何指针类型转化为void*类型，转化后，原值不变。但是ANSI C不允许所有的指针类型有相同的二进制表示法。

- 线程，线程提供一种并发能力，可以在一个进程中的同一时刻运行多个流。每个线程都有自己的硬件寄存器和堆栈。一个进程中的所有线程共享全部虚拟空间地址、所有文件描述、信号行为和其他的进程资源。相关函数介绍

- 互斥量提供了同步能力，可以控制线程如何共享资源。使用互斥量可以避免同一时刻多个线程修改共享的数据，并且保证一个线程能够从一套资源中读到一致性数据，其他线程可以修改这些资源（如内存）。相关函数介绍。

- 条件变量，提供通行功能，这种功能就是等待某些共享资源到达某个期望的状态，或者是在这些资源到达某种其他线程感兴趣的状态时，发出信号。条件变量与保护这种资源状态的互斥量紧密相关。相关函数介绍。

- 取消提供了一种方法：当你不再需要一个线程完成正常的执行过程时，温和地终止该线程。每个线程都能够控制“取消”如何影响自己，或者是否影响自己，并且因为取消而终止的线程，共享状态可以获得修复。相关函数介绍。

- 线程私有数据提供了一致方法来声明在所有的线程离有相同“名称”（但是对于每个线程值不同）的变量。在大多数方面，多线程程序里可以考虑使用线程私有数据，非线程化程序里可以考虑使用静态数据。例如，对某些函数，静态数据继续上下交叉的一系列调用时，环境关系通常就是线程的特定性关系（如果不是，互斥量就必须保护静态数据）。相关函数介绍。

- 实时调度在进程里为重要事件提供了可预测的响应时间。注意，这种“预测”并不意味着总是快的。在许多方面，实时调度可以利于这种“减慢执行”的限制。实时调度也遇到了同步的难题，例如优先级倒置，pthread提供了可选择的程序，用来解决部分难题。相关函数介绍。

- 分支处理程序pthread提供了一些新的函数以帮助新的线程环境与传统的基于线程的UNIX环境共存。如fork（分支）调用与该进程中的其他线程响应是异步的，拷贝全部的地址空间创建一个子进程，就会引发线程应用的困难。函数int thread_atfork（void  (*prepare)(void),void (*parent)(void), void (*child)(void));当进程创建了一个子进程时，定义要运行的“分支处理程序”|。允许在子进程里保护同步对象和共享数据（否则很难控制）。该函数头文件< unistd.h>错误描述为ENOMEM表示空间不足不能记录处理程序，提示必须保护子进程所需资源。

- stdio，pthread提供了一些新的函数和一些旧函数的新版本，可以从多线程进程中安全地访问ANSI C stdio。出于安全考虑，旧的访问stdio缓冲的single—character形式改变成给文件流加锁的方式，但这样会降低性能可以通过改变旧的代码以代替人工给文件流加锁；在需要锁定的区域里，可以使用新的特性访问没有给文件流加锁的操作。相关函数介绍：flockfile、ftrylockfile、funlockfile、getc_unlcoked、getchar_unlcoked、putc_unlocked、putchar_unlcoked.

- 线程安全函数改良了访问系统的ANSI C和POSIX的功能（该功能效率不高），而保持接口不变。传统函数名后缀加_r就是这些程序。相关函数：getlogin_r/readdir_r/strtok_r/asctime_r/ctime_r/gmtime_r/localtime_r/rand_r/getgrgid_r/getgrnam_r/getpwuid_r/getpwnam_r.

- 信号，pthread提供了POSIX信号模型的扩展函数，用以支撑多线程的进程。进程中的所有线程都共享同样的信号行为。每个线程都有自己待处理和阻塞的信号掩码。进程也有挂起信号的掩码，所以当所有的线程都有信号阻塞时，异同信号可以挂起。在多线程的进程中不定义sigprocmask行为。函数：pthread_kill/pthread_sigmask/sigtimedwait/sigwait/sigwaitinfo.

- 信号灯源于POSIX.1b（POSIX 1003.1b 1993），而不是pthread。它们遵循旧的UNIX报错习惯，发生错误时返回-1，并将相应的错误码保存在errno变量里。所有信号灯函数需要包含头文件< semaphore.h>.相关函数：sem_destroy/sem_init/sem_trywait/sem_post/sem_wait。

## 标准化过程展望

pthread程序员受三个主要的标准化研究成果影响大。X/Open的XSH5是一个新的接口规范，包含POSIX1.b、pthreads和一套附加的线程函数POSIX.1j草案标准提出增加barrier、读写锁、自旋锁（spinlock），并且改进了对条件变量的“相对时间”等待支持。POSIX 14草案标准（一个“POSIX标准子集”）指明了在多处理器环境下如何管理pthread的多种选项。

- X/Open XSH5[UNIX98]
介绍互斥量类型属性和读/写锁、并行I/O及其他。X/Open 是 The Group 的一部分，拥有UNIX商标并且发展了UNIX工业可移植性规范。它包括XPG3、UNIX93和UNIX95。UNIX95也被称为“SPEC1170”或“Single UNIX Specification".

- 在pthread标准中XSH5需要一些选项的特征值。如果你的编码是建立在这些选项的基础上，它就可以在任何兼容XSH5的系统下运行。

- DCE线程包提供了一个允许编程者规定所创建互斥量种类的扩展。DCE线程提供快速（fast）、可递归（recursive）和不可递归（nonrecursive）互斥量。

- 作为开发应用的人，只要你的编码不依赖于这样的实现，去检测（或失败检测）一些特殊的错误，你就可以交替地使用任何一个类型的互斥量，但绝不要编写基于没有任何错误检测的实现的代码。相关函数介绍：pthread_mutexattr_gettype/pthread_mutexattr_settype.

- 设置并发级别函数：pthread_getconcurrency/pthread_setconcurrency.

- 堆栈警戒尺寸，警戒尺寸来源于DCE thread。大多数线程实现为线程堆栈增加了一个警戒（guard）区域，增加了一页或者更多的保护内存。保护页是一个安全的区域，它们可以阻止线程内的堆栈溢出，避免破坏其他线程的堆栈。相关函数：pthread_attr_getguardsize/pthread_attr_setguardsize.

- 并行I/O，许多高性能系统如数据库引擎，至少在某些部分使用线程，并且通过其中的并行I/O以获取性能，但是pthread不直接支持并行I/O，即两个线程可以独立地执行文件I/O操作，甚至对同一个文件这样做，但是POSIX文件I/O模型在并行的级别上设置了一些限制。当前文件的位置是这个文件描述符的一个属性，为了从一个文件的特定区域读写数据，线程必须调用lseek，搜寻文件里合适的字节偏移量，然后再进行读写，如果不止一个线程在同一时间里这样做，第一个线程搜寻，然后第二个线程在第一个线程执行写操作之前将搜寻不同的地方。线程能够并行发布pread和pwrite操作。大体上，系统不用给文件描述符加锁就可以完全并行处理那些I/O请求。相关函数：pread、pwrite。

- 取消点，大多数UNIX系统都支持非POSIX的基本接口函数。介绍了XSH5中必须是取消点的附加函数和可能是取消点的附加函数。

- POSIX 1003.1j  条件变量等待时钟函数：返回值为int类型pthread_condattr_getclock/pthread_condattr_setclock.
Barriers变量函数：返回值为int类型。barrier_attr_init/barrier_attr_destroy/barrier_attr_getpshared/barrier_attr_setpshared/barrier_init/barrier_destroy/barrier_wait.
读/写锁变量函数：返回值为int类型rwlock_attr_init/rwlock_attr_destroy/rwlock_attr_getpshared/rwlock_attr_setpshared/rwlock_init/rwlock_destroy/rwlock_wlock/rwlock_timedwlock/rwlock_trywlock/rwlock_unlock.
自旋锁变量函数：返回值为int类型spin_init/spin_destroy/spin_lock/spin_trylock/spin_unlock/pthread_spin_init/pthread_spin_destroy/pthread_spin_lock/pthread_spin_trylock/pthread_spin_unlock.
thread异常中止返回的变量int pthread_abort(pthread_t thread);

- Barriers和自旋锁（spinlocks）有良好的并行粒度，例如，系统里从程序循环中自动生成并行操作代码。共享数据的算法中读/写锁非常有用，它允许多线程同时地读数据，但是只能有一个线程可以更新数据。

- barrier是一种同步形式，普遍应用与循环的并行分解。它们几乎只在多处理器系统中使用。一个barrier就是一组相关线程的”集合点“，每个线程都要在这里等候其他线程，直到所有的线程都到达这个barrier，当最后一个线程在barrier上等候时，释放所有参与等待的线程。

- 读/写锁允许一个线程专有地锁定某些共享的数据，并对该数据进行写或修改操作，页允许多个线程为了访问同时锁定这个数据。

- 自旋锁与互斥量非常相似。所给的硬件体系结构上，自旋锁是最简单和最快的合适的同步机制。两者关键区别是当另一个线程已经拥有了自旋锁时，一个试图给自旋锁加锁的线程不会被阻塞。即这个线程会”螺旋般“地再试着迅速加锁，直到它成功地给该自旋锁加上锁为止。自旋锁主要用于细粒度并行操作，当这个代码被设计为只在多处理器上运行时，仅需很少的指令、小心地调整，就可以拥有自旋锁，最终获得的性能要比与其他线程共享系统资源重要的多。更有效的是，作为线程间的“上下文开关”，自旋锁尽可能长时间地不被锁定。如果这种情况发生了，你可以通过阻塞，允许其他线程进行有用的工作而获得更高的性能。

- POSIX.1j包含两个自旋锁函数：一个是spin_prefix,它允许自旋锁在进程间同步；另一个是pthread_prefix,它允许自旋锁在一个进程里线程间同步。自旋锁预计会非常快，对任何可能的上限都不成问题，事实上，大多数系统上spin_lock和pthread_spin_loc的实现不同，但是标准允许它们不同。

- 条件变量等待时钟，pthread条件变量只支持绝对时间片。

- 线程异常中断，pthread_abort函数本质上是一个安全失败的取消函数，它用于需要使线程立即终止时。该函数危险的方面是该线程不允行清除处理程序或在这个线程之后没有任何其他机会去清除。即如果目标线程给一个互斥量加了锁，那么这个线程就会带着加锁的互斥量中止。因为不能从其他线程中给互斥量开锁，这个应用必须准备完全放弃互斥量，进一步说这就意味着任何等候这个放弃的互斥量的线程会永远等下去，直到调用pthread_abort函数中止这些线程。从而提高了实时响应能力。

- POSIX 1003.14，POSIX.14是一个不同类型的标准，一个”POSIX标准的子集“。对于多处理器硬件系统，POSIX.14指定哪一种POSIX可选行为应该被认为是”必须的“。同时也为不同的POSIX界限增加定义了最小值。 



程序：取消线程120页和129页，异步取消131页和135页承包线程137页线程私有数据142页和147页线程实时编程属性153页修改实时调度策略和参数155页和156页fork处理器172页输入出函数使用176页和179页用户终端181页线程推迟和继续188页信号处理函数197页通知机制使用200页信号灯205页barrier实现211页工作队列开发234页线程抢占252页

                                   整理于2014.9.8